{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing html content...: 30000it [00:06, 4902.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from housing_pricer.scraping.data_manager import DataManager\n",
    "from _booli_processing_utils import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import sys\n",
    "\n",
    "import plotly.express as px\n",
    "DATA_STORAGE = \"../../scraping/booli_final_prices/data_storage\"\n",
    "\n",
    "# n_listings = 0\n",
    "# for listings_html_content in tqdm(DataManager(DATA_STORAGE).load_data(), desc=\"Processing html content...\"):\n",
    "#     n_listings += 1\n",
    "# n_listings\n",
    "\n",
    "# LÄGENHET\n",
    "# KUNGSHOLMEN\n",
    "# ANTAL RUM\n",
    "# AVGIFT\n",
    "# DATUM SÅLD/BORTTAGEN\n",
    "# VÅNING\n",
    "# LGHNMR\n",
    "# ENERGIKLASS\n",
    "# DAGAR TILL SALU\n",
    "# BOSTADSRÄTTSFÖRENING (BRF): BRF INFO (NAMN, ÄKTA BRF Y/N, ANTAL BOSTÄDER, LÅN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stripping html response of superfluous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessingError(Exception):\n",
    "    \"\"\"Exception raised for errors in data processing.\"\"\"\n",
    "    def __init__(self, msg: str):\n",
    "        self.msg = msg\n",
    "        super().__init__(self.msg)\n",
    "\n",
    "def extract_relevant_data_as_json(html_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Process the HTML content and keep only essential data in JSON format.\n",
    "    \n",
    "    Args:\n",
    "    html_content: The HTML content as a string.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the filtered JSON data.\n",
    "\n",
    "    Raises:\n",
    "    DataProcessingError: If any step in the data processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_html = BeautifulSoup(html_content, \"lxml\")\n",
    "        parsed_relevant_section = parsed_html.find(\"script\", {\"id\": \"__NEXT_DATA__\"})\n",
    "\n",
    "        if isinstance(parsed_relevant_section, Tag) and parsed_relevant_section.string:\n",
    "            data_json = json.loads(parsed_relevant_section.string)\n",
    "            filtered_data_json = {key: data_json[key] for key in ['props', 'page', 'query'] if key in data_json}\n",
    "            return filtered_data_json\n",
    "        else:\n",
    "            raise DataProcessingError(\"Relevant script tag with specified id not found.\")\n",
    "    \n",
    "    except json.JSONDecodeError as exc:\n",
    "        raise DataProcessingError(\"Failed to decode JSON.\") from exc\n",
    "    except (KeyError, AttributeError) as exc:\n",
    "        raise DataProcessingError(\"Error accessing data.\") from exc\n",
    "    except Exception:\n",
    "        raise\n",
    "\n",
    "\n",
    "# data_json = extract_relevant_data_as_json(listings_html_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Re-converting data: 30000it [03:28, 143.96it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open(\"data_temp.gz\", \"ab\") as fhandle:\n",
    "    for listings_html_content in tqdm(DataManager(DATA_STORAGE).load_data(), desc=\"Re-converting data\"):\n",
    "        data_json = extract_relevant_data_as_json(listings_html_content)\n",
    "        pickle.dump(data_json, fhandle)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_LISTINGS_TO_PROCESS = 1000\n",
    "# data = list(islice(DataManager(DATA_STORAGE).load_data(), N_LISTINGS_TO_PROCESS))\n",
    "\n",
    "# def _process_listing_html(listing_html_content):\n",
    "#     try:\n",
    "#         listing_info = extract_ad_info(listing_html_content)\n",
    "#         return listing_info\n",
    "#     except Exception as exc:\n",
    "#         print(exc)\n",
    "#         return None\n",
    "\n",
    "# parallel = Parallel(n_jobs=-1)\n",
    "# delayed_jobs = (delayed(_process_listing_html)(html) for html in data)\n",
    "# processed_listings = [job for job in parallel(delayed_jobs) if job is not None]\n",
    "# pd.DataFrame(processed_listings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e33bb7b2cc010271644b84a13393be6366e525871ad6044d36d413a1c22c2e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
